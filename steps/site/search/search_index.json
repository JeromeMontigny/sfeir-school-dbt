{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"SFEIR Institute - dbt Navigate through the modules and labs using this static website to review exercice and solutions.","title":"SFEIR Institute - dbt"},{"location":"index.html#sfeir-institute-dbt","text":"Navigate through the modules and labs using this static website to review exercice and solutions.","title":"SFEIR Institute - dbt"},{"location":"module_03/lab-1/index.html","text":"Module 3 - Lab 1 Task Create a \"products\" model with the provided sample SQL file, and apply different options to test dbt features. SQL File : products.sql Tips Disable partial_parsing in your profile configuration The sample provided is compatible with Postgres. If you use another adapter, you may have to edit it. Todo Use the SQL provided to create a simple \"products\" model, in the \"models/institute\" subdirectory. Execute dbt run command and see what happens Fix the problem and run dbt again Copy this file with the exact same name in another subdirectory within models and run dbt again What happens ? Create a model property file, referencing this new model Rename the model file only and execute dbt run What happens ? Look carefuly at the execution log Undo your change and rollback to products name for your model Change the destination schema to \"lab\" using your dbt_project file, and use \"table\" as materialization In what schema will dbt materialize your model ? Add tags \"institute\" and \"static\" to your model using 3 different methods Try filtering your run command using tags Cleanup Remove the model in your dbt code, and optionnaly the table / view also","title":"Tasks"},{"location":"module_03/lab-1/index.html#module-3-lab-1","text":"","title":"Module 3 - Lab 1"},{"location":"module_03/lab-1/index.html#task","text":"Create a \"products\" model with the provided sample SQL file, and apply different options to test dbt features. SQL File : products.sql","title":"Task"},{"location":"module_03/lab-1/index.html#tips","text":"Disable partial_parsing in your profile configuration The sample provided is compatible with Postgres. If you use another adapter, you may have to edit it.","title":"Tips"},{"location":"module_03/lab-1/index.html#todo","text":"Use the SQL provided to create a simple \"products\" model, in the \"models/institute\" subdirectory. Execute dbt run command and see what happens Fix the problem and run dbt again Copy this file with the exact same name in another subdirectory within models and run dbt again What happens ? Create a model property file, referencing this new model Rename the model file only and execute dbt run What happens ? Look carefuly at the execution log Undo your change and rollback to products name for your model Change the destination schema to \"lab\" using your dbt_project file, and use \"table\" as materialization In what schema will dbt materialize your model ? Add tags \"institute\" and \"static\" to your model using 3 different methods Try filtering your run command using tags","title":"Todo"},{"location":"module_03/lab-1/index.html#cleanup","text":"Remove the model in your dbt code, and optionnaly the table / view also","title":"Cleanup"},{"location":"module_03/lab-1/SOLUTION.html","text":"Module 3 - Lab 1 - Solution Use the SQL provided to create a simple \"products\" model. In the models/institute subdirectory, create a file name \"products.sql\" and simply copy the SQL from sample. Execute dbt run command and see what happens The problem is the \";\" at the end of the SQL. Indeed, dbt wraps your SQL code in a CREATE TABLE or CREATE VIEW, and this would produce invalid SQL. Copy the SQL file (keep the same name) in another subdirectory within models and run dbt again dbt cannot run because there is a naming conflict: all models name must be unique in your project. Create a model definition file, referencing this new model In the same folder, create a YAML file (for instance __models.yml ) with this content: models: - name: products - name: customers Rename the model file only and re-run dbt run --> what happens ? A new model with the new name is created by dbt, which also outputs a warning because the property file references an inexisting model. Change the destination schema to \"lab\" using your dbt_project file ... ... models: sfeir_institute: # Don't forget the name of your project here... institute: +schema: lab +materialized: table ... The actual target schema will be \"xxx_lab\", and not just \"lab\" (xxx is your default schema name in profiles.yml) Add tags \"institute\" and \"static\" to your model using 3 different methods In the SQL file: {{ config( tags=[\"institute\", \"static\"] ) }} -- SQL below this line In the models definition file: models: - name: products config: tags: - institute - static In the dbt_project file: ... models: sfeir_institute: # Don't forget the name of your project here... institute: +schema: lab +materialized: table +tags: [\"institute\", \"static\"] ...","title":"Solution"},{"location":"module_03/lab-1/SOLUTION.html#module-3-lab-1-solution","text":"","title":"Module 3 - Lab 1 - Solution"},{"location":"module_03/lab-1/SOLUTION.html#use-the-sql-provided-to-create-a-simple-products-model","text":"In the models/institute subdirectory, create a file name \"products.sql\" and simply copy the SQL from sample.","title":"Use the SQL provided to create a simple \"products\" model."},{"location":"module_03/lab-1/SOLUTION.html#execute-dbt-run-command-and-see-what-happens","text":"The problem is the \";\" at the end of the SQL. Indeed, dbt wraps your SQL code in a CREATE TABLE or CREATE VIEW, and this would produce invalid SQL.","title":"Execute dbt run command and see what happens"},{"location":"module_03/lab-1/SOLUTION.html#copy-the-sql-file-keep-the-same-name-in-another-subdirectory-within-models-and-run-dbt-again","text":"dbt cannot run because there is a naming conflict: all models name must be unique in your project.","title":"Copy the SQL file (keep the same name) in another subdirectory within models and run dbt again"},{"location":"module_03/lab-1/SOLUTION.html#create-a-model-definition-file-referencing-this-new-model","text":"In the same folder, create a YAML file (for instance __models.yml ) with this content: models: - name: products - name: customers","title":"Create a model definition file, referencing this new model"},{"location":"module_03/lab-1/SOLUTION.html#rename-the-model-file-only-and-re-run-dbt-run-what-happens","text":"A new model with the new name is created by dbt, which also outputs a warning because the property file references an inexisting model.","title":"Rename the model file only and re-run dbt run --&gt; what happens ?"},{"location":"module_03/lab-1/SOLUTION.html#change-the-destination-schema-to-lab-using-your-dbt_project-file","text":"... ... models: sfeir_institute: # Don't forget the name of your project here... institute: +schema: lab +materialized: table ... The actual target schema will be \"xxx_lab\", and not just \"lab\" (xxx is your default schema name in profiles.yml)","title":"Change the destination schema to \"lab\" using your dbt_project file"},{"location":"module_03/lab-1/SOLUTION.html#add-tags-institute-and-static-to-your-model-using-3-different-methods","text":"In the SQL file: {{ config( tags=[\"institute\", \"static\"] ) }} -- SQL below this line In the models definition file: models: - name: products config: tags: - institute - static In the dbt_project file: ... models: sfeir_institute: # Don't forget the name of your project here... institute: +schema: lab +materialized: table +tags: [\"institute\", \"static\"] ...","title":"Add tags \"institute\" and \"static\" to your model using 3 different methods"},{"location":"module_04/lab-1/index.html","text":"Task Use source() and ref() functions to create dependencies between models. Tips Your trainer will give you access to an existing database with a few tables. Todo Create a sources definition file with the provided tables Create a \"stg__orders\" model using the sales source, with completed and cancelled orders only. Use this model and join with customers and countries to create \"int__orders\", and add the following fields only: Customer name Customer country name Run a single model, then all the depending models, or the dependencies of this model Add column list to your \"int_orders model\" Add a new column to the model What happens ? Add a new column to the property file What happens ? Create 2 new models referencing each others respectively Try to run dbt with these 2 new models Bonus: * Add freshness configuration to the orders table in the sales source * Warning after 1 week, error after 1 month * Try to make the freshness command warn and/or fail * Try avoiding the effective creation of the \"stg__orders\" model in your database","title":"Tasks"},{"location":"module_04/lab-1/index.html#task","text":"Use source() and ref() functions to create dependencies between models.","title":"Task"},{"location":"module_04/lab-1/index.html#tips","text":"Your trainer will give you access to an existing database with a few tables.","title":"Tips"},{"location":"module_04/lab-1/index.html#todo","text":"Create a sources definition file with the provided tables Create a \"stg__orders\" model using the sales source, with completed and cancelled orders only. Use this model and join with customers and countries to create \"int__orders\", and add the following fields only: Customer name Customer country name Run a single model, then all the depending models, or the dependencies of this model Add column list to your \"int_orders model\" Add a new column to the model What happens ? Add a new column to the property file What happens ? Create 2 new models referencing each others respectively Try to run dbt with these 2 new models Bonus: * Add freshness configuration to the orders table in the sales source * Warning after 1 week, error after 1 month * Try to make the freshness command warn and/or fail * Try avoiding the effective creation of the \"stg__orders\" model in your database","title":"Todo"},{"location":"module_04/lab-1/SOLUTION.html","text":"Solution Create sources with the provided tables models/institute/__sources.yml sources: - name: sales schema: sales tables: - name: categories - name: companies - name: customers - name: countries - name: orders Create a \"stg__orders\" model using the sales source, with completed and cancelled orders only /models/institute/stg__orders.sql SELECT * FROM {{ source(\"sales\", \"orders\") }} WHERE order_status IN ('COMPLETED', 'CANCELLED') Use this model and join with customers and countries to create \"int__orders\" You should create staging tables first. Don't mix source() and ref() in the same \"int\" model. /models/institute/int__orders.sql SELECT orders.* , customers.customer_name , countries.country_name FROM {{ ref(\"stg__orders\") }} AS orders INNER JOIN {{ ref(\"stg__customers\") }} AS customers ON customers.customer_id = orders.customer_id INNER JOIN {{ ref(\"stg__countries\") }} AS countries ON customers.customer_country = countries.country_code Run a single model, then all the depending models, or the dependencies of this model $ dbt run --select int__orders $ dbt run --select +int__orders $ dbt run --select stg__orders+ Add column list to your \"int_orders\" model and then modify the model and property file Nothing will happen if you add columns to the model or the property file because it's declarative only and there is no control. Yet... Create 2 new models referencing each others respectively dbt will not run because of the circular reference: it cannot create an DAG with a correct order of execution. Bonus Add freshness configuration to the sales source models/institute/__sources.yml sources: - name: sales schema: sales tables: - name: customers - name: countries - name: sales freshness: warn_after: {count: 7, period: day} error_after: {count: 30, period: day} loaded_at_field: order_datetime - name: categories - name: companies To make the command fail, change the period for warn and error (you can use negative numbers if needed...) Try avoiding the creation of the filtered sales model in your database models/institute/__models.yml models: - name: stg__orders config: materialized: ephemeral - name: int__sales","title":"Solution"},{"location":"module_04/lab-1/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_04/lab-1/SOLUTION.html#create-sources-with-the-provided-tables","text":"models/institute/__sources.yml sources: - name: sales schema: sales tables: - name: categories - name: companies - name: customers - name: countries - name: orders","title":"Create sources with the provided tables"},{"location":"module_04/lab-1/SOLUTION.html#create-a-stg__orders-model-using-the-sales-source-with-completed-and-cancelled-orders-only","text":"/models/institute/stg__orders.sql SELECT * FROM {{ source(\"sales\", \"orders\") }} WHERE order_status IN ('COMPLETED', 'CANCELLED')","title":"Create a \"stg__orders\" model using the sales source, with completed and cancelled orders only"},{"location":"module_04/lab-1/SOLUTION.html#use-this-model-and-join-with-customers-and-countries-to-create-int__orders","text":"You should create staging tables first. Don't mix source() and ref() in the same \"int\" model. /models/institute/int__orders.sql SELECT orders.* , customers.customer_name , countries.country_name FROM {{ ref(\"stg__orders\") }} AS orders INNER JOIN {{ ref(\"stg__customers\") }} AS customers ON customers.customer_id = orders.customer_id INNER JOIN {{ ref(\"stg__countries\") }} AS countries ON customers.customer_country = countries.country_code","title":"Use this model and join with customers and countries to create \"int__orders\""},{"location":"module_04/lab-1/SOLUTION.html#run-a-single-model-then-all-the-depending-models-or-the-dependencies-of-this-model","text":"$ dbt run --select int__orders $ dbt run --select +int__orders $ dbt run --select stg__orders+","title":"Run a single model, then all the depending models, or the dependencies of this model"},{"location":"module_04/lab-1/SOLUTION.html#add-column-list-to-your-int_orders-model-and-then-modify-the-model-and-property-file","text":"Nothing will happen if you add columns to the model or the property file because it's declarative only and there is no control. Yet...","title":"Add column list to your \"int_orders\" model and then modify the model and property file"},{"location":"module_04/lab-1/SOLUTION.html#create-2-new-models-referencing-each-others-respectively","text":"dbt will not run because of the circular reference: it cannot create an DAG with a correct order of execution.","title":"Create 2 new models referencing each others respectively"},{"location":"module_04/lab-1/SOLUTION.html#bonus","text":"","title":"Bonus"},{"location":"module_04/lab-1/SOLUTION.html#add-freshness-configuration-to-the-sales-source","text":"models/institute/__sources.yml sources: - name: sales schema: sales tables: - name: customers - name: countries - name: sales freshness: warn_after: {count: 7, period: day} error_after: {count: 30, period: day} loaded_at_field: order_datetime - name: categories - name: companies To make the command fail, change the period for warn and error (you can use negative numbers if needed...)","title":"Add freshness configuration to the sales source"},{"location":"module_04/lab-1/SOLUTION.html#try-avoiding-the-creation-of-the-filtered-sales-model-in-your-database","text":"models/institute/__models.yml models: - name: stg__orders config: materialized: ephemeral - name: int__sales","title":"Try avoiding the creation of the filtered sales model in your database"},{"location":"module_04/lab-2/index.html","text":"Task Using what you've leaned so far, create incremental model. Tips Use the following query to update orders and test your incremental logic once it's done. UPDATE \"sales\".\"orders\" SET order_datetime = NOW(), order_status = 'COMPLETED' WHERE random() < 0.1 AND order_status != 'COMPLETED'; Todo Update your stg__orders model to remove the filter on order status. In a new folder, create a model in your project with the following specifications Use a date or datetime field for incremental logic Create a second model with the same specs but with a unique key on: order_id order_line_id Run dbt twice on the new models and their dependencies What happens ? Update the source orders table with the query provided and run your models again Compare the 2 new models Run the models again with the full_refresh option Did you lose any data ? Can you prevent this loss ?","title":"Tasks"},{"location":"module_04/lab-2/index.html#task","text":"Using what you've leaned so far, create incremental model.","title":"Task"},{"location":"module_04/lab-2/index.html#tips","text":"Use the following query to update orders and test your incremental logic once it's done. UPDATE \"sales\".\"orders\" SET order_datetime = NOW(), order_status = 'COMPLETED' WHERE random() < 0.1 AND order_status != 'COMPLETED';","title":"Tips"},{"location":"module_04/lab-2/index.html#todo","text":"Update your stg__orders model to remove the filter on order status. In a new folder, create a model in your project with the following specifications Use a date or datetime field for incremental logic Create a second model with the same specs but with a unique key on: order_id order_line_id Run dbt twice on the new models and their dependencies What happens ? Update the source orders table with the query provided and run your models again Compare the 2 new models Run the models again with the full_refresh option Did you lose any data ? Can you prevent this loss ?","title":"Todo"},{"location":"module_04/lab-2/SOLUTION.html","text":"Solution In a new folder, create a model in your project with the following specifications models/institute/incremental/int__orders_incremental_1.sql {{ config( materialized='incremental', ) }} SELECT * FROM {{ ref(\"stg__orders\") }} {% if is_incremental() %} WHERE order_datetime > (SELECT MAX(order_datetime) FROM {{ this }}) {% endif %} Create a second model with the same specs but with a unique key on order_id and order_line_id models/institute/incremental/int__orders_incremental_2.sql {{ config( materialized='incremental', unique_key=['order_id', 'order_line_id'] ) }} SELECT * FROM {{ ref(\"stg__orders\") }} {% if is_incremental() %} WHERE order_datetime > (SELECT MAX(order_datetime) FROM {{ this }}) {% endif %} Run dbt twice on the new models and their dependencies Use this command to run the new models and their dependencies only: dbt run -s +institute.incremental The first run reads and insert 10000 lines in both new models. The second run reads and does not insert any line in either of the model. Update the source orders table with the query provided and run your models again Run this query to update a random number of orders in your source UPDATE \"sales\".\"orders\" SET order_datetime = NOW(), order_status = 'COMPLETED' WHERE random() < 0.1 AND order_status != 'COMPLETED'; Run dbt with the same command and look at the results. Use count queries to compare the volume of your incremental models. The difference comes from the unique keys: - Without, dbt stacks new lines on top of the existing ones - With unique key, dbt replace the old lines with the new ones Run the models again with the full_refresh option Because of the full-refresh option, dbt dropped the previous models and replaced them from scratch. You actually lost the history of status of orders because it is now changed forever in the source.","title":"Solution"},{"location":"module_04/lab-2/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_04/lab-2/SOLUTION.html#in-a-new-folder-create-a-model-in-your-project-with-the-following-specifications","text":"models/institute/incremental/int__orders_incremental_1.sql {{ config( materialized='incremental', ) }} SELECT * FROM {{ ref(\"stg__orders\") }} {% if is_incremental() %} WHERE order_datetime > (SELECT MAX(order_datetime) FROM {{ this }}) {% endif %}","title":"In a new folder, create a model in your project with the following specifications"},{"location":"module_04/lab-2/SOLUTION.html#create-a-second-model-with-the-same-specs-but-with-a-unique-key-on-order_id-and-order_line_id","text":"models/institute/incremental/int__orders_incremental_2.sql {{ config( materialized='incremental', unique_key=['order_id', 'order_line_id'] ) }} SELECT * FROM {{ ref(\"stg__orders\") }} {% if is_incremental() %} WHERE order_datetime > (SELECT MAX(order_datetime) FROM {{ this }}) {% endif %}","title":"Create a second model with the same specs but with a unique key on order_id and order_line_id"},{"location":"module_04/lab-2/SOLUTION.html#run-dbt-twice-on-the-new-models-and-their-dependencies","text":"Use this command to run the new models and their dependencies only: dbt run -s +institute.incremental The first run reads and insert 10000 lines in both new models. The second run reads and does not insert any line in either of the model.","title":"Run dbt twice on the new models and their dependencies"},{"location":"module_04/lab-2/SOLUTION.html#update-the-source-orders-table-with-the-query-provided-and-run-your-models-again","text":"Run this query to update a random number of orders in your source UPDATE \"sales\".\"orders\" SET order_datetime = NOW(), order_status = 'COMPLETED' WHERE random() < 0.1 AND order_status != 'COMPLETED'; Run dbt with the same command and look at the results. Use count queries to compare the volume of your incremental models. The difference comes from the unique keys: - Without, dbt stacks new lines on top of the existing ones - With unique key, dbt replace the old lines with the new ones","title":"Update the source orders table with the query provided and run your models again"},{"location":"module_04/lab-2/SOLUTION.html#run-the-models-again-with-the-full_refresh-option","text":"Because of the full-refresh option, dbt dropped the previous models and replaced them from scratch. You actually lost the history of status of orders because it is now changed forever in the source.","title":"Run the models again with the full_refresh option"},{"location":"module_05/lab-1/index.html","text":"Task Import data from CSV files in your warehouse. Seed files : seed_categories seed_companies seed_countries Todo Copy the sample seed files to import them in your warehouse using seeds See how dbt names object from the filenames and think about potential issues Using your dbt_project.yml file, change the destination schema of all your seeds Set the schema to dbt_seeds Look in the dbt documentation to remove the \"seed_\" part of the destination seed tables Update the \"categories\" seeds to explicitely define column types: category_code AS varchar(8) category_name AS varchar(32) enabled AS boolean date_in AS timestamp Cleanup Remove all the seeds from outside of the good schema, and with the \"wrong names\"","title":"Tasks"},{"location":"module_05/lab-1/index.html#task","text":"Import data from CSV files in your warehouse. Seed files : seed_categories seed_companies seed_countries","title":"Task"},{"location":"module_05/lab-1/index.html#todo","text":"Copy the sample seed files to import them in your warehouse using seeds See how dbt names object from the filenames and think about potential issues Using your dbt_project.yml file, change the destination schema of all your seeds Set the schema to dbt_seeds Look in the dbt documentation to remove the \"seed_\" part of the destination seed tables Update the \"categories\" seeds to explicitely define column types: category_code AS varchar(8) category_name AS varchar(32) enabled AS boolean date_in AS timestamp","title":"Todo"},{"location":"module_05/lab-1/index.html#cleanup","text":"Remove all the seeds from outside of the good schema, and with the \"wrong names\"","title":"Cleanup"},{"location":"module_05/lab-1/SOLUTION.html","text":"Solution Using your dbt_project.yml file, change the destination schema of all your seeds ... seeds: +schema: seeds or: ... seeds: sfeir_institute: +schema: seeds Look in the documentation to remove the \"seed_\" part of the destination seed tables seeds/__seeds.yml seeds: - name: seed_categories config: alias: categories - name: seed_companies config: alias: companies - name: seed_countries config: alias: countries Update the \"categories\" seeds to explicitely define column types: seeds/__seeds.yml seeds: - name: seed_categories config: alias: categories column_types: category_code: varchar(8) category_name: varchar(32) enabled: boolean date_in: timestamp You will need to run dbt seed with --full-refresh option or the change won't take effect when you change column types.","title":"Solution"},{"location":"module_05/lab-1/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_05/lab-1/SOLUTION.html#using-your-dbt_projectyml-file-change-the-destination-schema-of-all-your-seeds","text":"... seeds: +schema: seeds or: ... seeds: sfeir_institute: +schema: seeds","title":"Using your dbt_project.yml file, change the destination schema of all your seeds"},{"location":"module_05/lab-1/SOLUTION.html#look-in-the-documentation-to-remove-the-seed_-part-of-the-destination-seed-tables","text":"seeds/__seeds.yml seeds: - name: seed_categories config: alias: categories - name: seed_companies config: alias: companies - name: seed_countries config: alias: countries","title":"Look in the documentation to remove the \"seed_\" part of the destination seed tables"},{"location":"module_05/lab-1/SOLUTION.html#update-the-categories-seeds-to-explicitely-define-column-types","text":"seeds/__seeds.yml seeds: - name: seed_categories config: alias: categories column_types: category_code: varchar(8) category_name: varchar(32) enabled: boolean date_in: timestamp You will need to run dbt seed with --full-refresh option or the change won't take effect when you change column types.","title":"Update the \"categories\" seeds to explicitely define column types:"},{"location":"module_06/lab-1/index.html","text":"Task Declare and run snapshots using both strategies Tips Use the following query to update orders and test your snapshot logic once it's done. Don't forget to refresh your stg__models after the update / delete operations UPDATE \"sales\".\"orders\" SET order_datetime = NOW(), order_status = 'COMPLETED' WHERE random() < 0.1 AND order_status != 'COMPLETED'; To delete lines in your orders table, run the following query: DELETE FROM \"sales\".\"orders\" WHERE random() < 0.05; Todo Create a snapshot on your stg__orders model keep track of changes in all fields as if there was no order_datetime field use order_id as unique_key Create a snapshot on your int__orders model Keep track of changes to order_status only based on order_datetime value use order_id as unique_key Run dbt and compare the snapshot tables created Update your orders sources using the provided query and run snapshots again Looking at the numbers, there seems to be a problem with the change detection Fix the problem and recreate the snapshots Add support for hard deletes in your snapshots Delete a few lines in your source to test the feature Refresh your stg__orders models Run snapshots again","title":"Tasks"},{"location":"module_06/lab-1/index.html#task","text":"Declare and run snapshots using both strategies","title":"Task"},{"location":"module_06/lab-1/index.html#tips","text":"Use the following query to update orders and test your snapshot logic once it's done. Don't forget to refresh your stg__models after the update / delete operations UPDATE \"sales\".\"orders\" SET order_datetime = NOW(), order_status = 'COMPLETED' WHERE random() < 0.1 AND order_status != 'COMPLETED'; To delete lines in your orders table, run the following query: DELETE FROM \"sales\".\"orders\" WHERE random() < 0.05;","title":"Tips"},{"location":"module_06/lab-1/index.html#todo","text":"Create a snapshot on your stg__orders model keep track of changes in all fields as if there was no order_datetime field use order_id as unique_key Create a snapshot on your int__orders model Keep track of changes to order_status only based on order_datetime value use order_id as unique_key Run dbt and compare the snapshot tables created Update your orders sources using the provided query and run snapshots again Looking at the numbers, there seems to be a problem with the change detection Fix the problem and recreate the snapshots Add support for hard deletes in your snapshots Delete a few lines in your source to test the feature Refresh your stg__orders models Run snapshots again","title":"Todo"},{"location":"module_06/lab-1/SOLUTION.html","text":"Solution Create a snapshot on your stg__orders model {% snapshot orders_1 %} {{ config( target_schema='snapshots', unique_key='order_id', strategy='check', check_cols='all' ) }} SELECT * FROM {{ ref('stg__orders') }} {% endsnapshot %} Create a second snapshot on your stg__orders model {% snapshot orders_2 %} {{ config( target_schema='snapshots', unique_key='order_id', strategy='timestamp', updated_at='order_datetime' ) }} SELECT order_id, order_status, order_datetime FROM {{ ref('stg__orders') }} {% endsnapshot %} Run dbt and compare the snapshot tables created dbt adds 4 fields to support the snapshot stragegy and comparison mechanism. You can use dbt_valid_from and dbt_valid_to to query the snapshots for historical data. Update your orders sources using the provided query and run snapshots again Use this query to update your source. UPDATE \"sales\".\"orders\" SET order_datetime = NOW(), order_status = 'COMPLETED' WHERE random() < 0.1 AND order_status != 'COMPLETED'; Update your stg__orders model to reflect changes in the source (dbt run -s stg__orders). Run the snapshots and look for rows with not null dbt_valid_to fields. Looking at the numbers, there seems to be a problem with the change detection The orders model has a compound unique key (order_id and order_line_id) and you can't define an array of keys in snapshots. However, you can put valid SQL in the unique_key parameter. {% snapshot orders_1 %} {{ config( target_schema='snapshots', unique_key='CONCAT(order_id, order_line_id)', strategy='check', check_cols='all' ) }} SELECT * FROM {{ ref('stg__orders') }} {% endsnapshot %} Add support for hard deletes in your snapshots Use this SQL to delete lines from your source and refresh your dbt model afterwards. DELETE FROM \"sales\".\"orders\" WHERE random() < 0.05; Add the invalidate_hard_deletes option to your snapshots. {% snapshot orders_1 %} {{ config( target_schema='snapshots', unique_key='CONCAT(order_id, order_line_id)', strategy='check', check_cols='all', invalidate_hard_deletes=True ) }} SELECT * FROM {{ ref('stg__orders') }} {% endsnapshot %} Run the snapshot again and look for rows with dbt_valid_to set to your snapshot execution date, and no other row with the same unique keys and dbt_valid_to set to null.","title":"Solution"},{"location":"module_06/lab-1/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_06/lab-1/SOLUTION.html#create-a-snapshot-on-your-stg__orders-model","text":"{% snapshot orders_1 %} {{ config( target_schema='snapshots', unique_key='order_id', strategy='check', check_cols='all' ) }} SELECT * FROM {{ ref('stg__orders') }} {% endsnapshot %}","title":"Create a snapshot on your stg__orders model"},{"location":"module_06/lab-1/SOLUTION.html#create-a-second-snapshot-on-your-stg__orders-model","text":"{% snapshot orders_2 %} {{ config( target_schema='snapshots', unique_key='order_id', strategy='timestamp', updated_at='order_datetime' ) }} SELECT order_id, order_status, order_datetime FROM {{ ref('stg__orders') }} {% endsnapshot %}","title":"Create a second snapshot on your stg__orders model"},{"location":"module_06/lab-1/SOLUTION.html#run-dbt-and-compare-the-snapshot-tables-created","text":"dbt adds 4 fields to support the snapshot stragegy and comparison mechanism. You can use dbt_valid_from and dbt_valid_to to query the snapshots for historical data.","title":"Run dbt and compare the snapshot tables created"},{"location":"module_06/lab-1/SOLUTION.html#update-your-orders-sources-using-the-provided-query-and-run-snapshots-again","text":"Use this query to update your source. UPDATE \"sales\".\"orders\" SET order_datetime = NOW(), order_status = 'COMPLETED' WHERE random() < 0.1 AND order_status != 'COMPLETED'; Update your stg__orders model to reflect changes in the source (dbt run -s stg__orders). Run the snapshots and look for rows with not null dbt_valid_to fields.","title":"Update your orders sources using the provided query and run snapshots again"},{"location":"module_06/lab-1/SOLUTION.html#looking-at-the-numbers-there-seems-to-be-a-problem-with-the-change-detection","text":"The orders model has a compound unique key (order_id and order_line_id) and you can't define an array of keys in snapshots. However, you can put valid SQL in the unique_key parameter. {% snapshot orders_1 %} {{ config( target_schema='snapshots', unique_key='CONCAT(order_id, order_line_id)', strategy='check', check_cols='all' ) }} SELECT * FROM {{ ref('stg__orders') }} {% endsnapshot %}","title":"Looking at the numbers, there seems to be a problem with the change detection"},{"location":"module_06/lab-1/SOLUTION.html#add-support-for-hard-deletes-in-your-snapshots","text":"Use this SQL to delete lines from your source and refresh your dbt model afterwards. DELETE FROM \"sales\".\"orders\" WHERE random() < 0.05; Add the invalidate_hard_deletes option to your snapshots. {% snapshot orders_1 %} {{ config( target_schema='snapshots', unique_key='CONCAT(order_id, order_line_id)', strategy='check', check_cols='all', invalidate_hard_deletes=True ) }} SELECT * FROM {{ ref('stg__orders') }} {% endsnapshot %} Run the snapshot again and look for rows with dbt_valid_to set to your snapshot execution date, and no other row with the same unique keys and dbt_valid_to set to null.","title":"Add support for hard deletes in your snapshots"},{"location":"module_07/lab-1/index.html","text":"Task Use variables and macros to make your code more efficient and maintainable Todo Create and use 2 variables to replace COMPLETED and CANCELLED filter in your stg__orders model Change the values at run time using \"--vars\" to alter models output Create another variable to filter orders in int__orders If the variable is empty, don't filter If the variable is set, keep only orders placed after the date set Create and use a macro to compute the turnover of orders in the int__orders model The turnover formula should be: base_price * quantity - rebate converted in EUR consider that 1 EUR = 1.1 USD","title":"Tasks"},{"location":"module_07/lab-1/index.html#task","text":"Use variables and macros to make your code more efficient and maintainable","title":"Task"},{"location":"module_07/lab-1/index.html#todo","text":"Create and use 2 variables to replace COMPLETED and CANCELLED filter in your stg__orders model Change the values at run time using \"--vars\" to alter models output Create another variable to filter orders in int__orders If the variable is empty, don't filter If the variable is set, keep only orders placed after the date set Create and use a macro to compute the turnover of orders in the int__orders model The turnover formula should be: base_price * quantity - rebate converted in EUR consider that 1 EUR = 1.1 USD","title":"Todo"},{"location":"module_07/lab-1/SOLUTION.html","text":"Solution Create and use 2 variables to replace COMPLETED and CANCELLED filter in your stg__orders model dbt_project.yml ... vars: sfeir_institute: status_completed: 'COMPLETED' status_cancelled: 'CANCELLED' models/institute/stg__orders.sql SELECT * FROM {{ source(\"sales\", \"orders\") }} WHERE order_status IN ('{{ var(\"status_completed\") }}', '{{ var(\"status_cancelled\")}}') Change the values at run time using \"--vars\" to alter models output # Don't forget the space after : $ dbt run --vars 'status_completed: FOOBAR' # or $ dbt run --vars '{\"status_completed\": \"NONE\"}' Create another variable to filter orders in int__orders dbt_project.yml ... vars: sfeir_institute: status_completed: 'COMPLETED' status_cancelled: 'CANCELLED' order_filter: models/institute/int__orders.sql SELECT orders.* , customers.customer_name , countries.country_name FROM {{ ref(\"stg__orders\") }} AS orders INNER JOIN {{ ref(\"stg__customers\") }} AS customers ON customers.customer_id = orders.customer_id INNER JOIN {{ ref(\"stg__countries\") }} AS countries ON customers.customer_country = countries.country_code WHERE TRUE {% if var(\"order_filter\") %} AND order_datetime > '{{ var(\"order_filter\") }}' {% endif %} Create and use a macro to compute the turnover of orders in the int__orders model macros/macro_turnover.sql {% macro turnover() %} ( (base_price * quantity - rebate) * CASE currency WHEN 'EUR' THEN 1 WHEN 'USD' THEN 1.1 END ) {% endmacro %} models/institute/int__sales.sql SELECT orders.* , customers.customer_name , countries.country_name , {{ turnover() }} AS turnover FROM {{ ref(\"stg__orders\") }} AS orders INNER JOIN {{ ref(\"stg__customers\") }} AS customers ON customers.customer_id = orders.customer_id INNER JOIN {{ ref(\"stg__countries\") }} AS countries ON customers.customer_country = countries.country_code WHERE TRUE {% if var(\"order_filter\") %} AND order_datetime > '{{ var(\"order_filter\") }}' {% endif %}","title":"Solution"},{"location":"module_07/lab-1/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_07/lab-1/SOLUTION.html#create-and-use-2-variables-to-replace-completed-and-cancelled-filter-in-your-stg__orders-model","text":"dbt_project.yml ... vars: sfeir_institute: status_completed: 'COMPLETED' status_cancelled: 'CANCELLED' models/institute/stg__orders.sql SELECT * FROM {{ source(\"sales\", \"orders\") }} WHERE order_status IN ('{{ var(\"status_completed\") }}', '{{ var(\"status_cancelled\")}}')","title":"Create and use 2 variables to replace COMPLETED and CANCELLED filter in your stg__orders model"},{"location":"module_07/lab-1/SOLUTION.html#change-the-values-at-run-time-using-vars-to-alter-models-output","text":"# Don't forget the space after : $ dbt run --vars 'status_completed: FOOBAR' # or $ dbt run --vars '{\"status_completed\": \"NONE\"}'","title":"Change the values at run time using \"--vars\" to alter models output"},{"location":"module_07/lab-1/SOLUTION.html#create-another-variable-to-filter-orders-in-int__orders","text":"dbt_project.yml ... vars: sfeir_institute: status_completed: 'COMPLETED' status_cancelled: 'CANCELLED' order_filter: models/institute/int__orders.sql SELECT orders.* , customers.customer_name , countries.country_name FROM {{ ref(\"stg__orders\") }} AS orders INNER JOIN {{ ref(\"stg__customers\") }} AS customers ON customers.customer_id = orders.customer_id INNER JOIN {{ ref(\"stg__countries\") }} AS countries ON customers.customer_country = countries.country_code WHERE TRUE {% if var(\"order_filter\") %} AND order_datetime > '{{ var(\"order_filter\") }}' {% endif %}","title":"Create another variable to filter orders in int__orders"},{"location":"module_07/lab-1/SOLUTION.html#create-and-use-a-macro-to-compute-the-turnover-of-orders-in-the-int__orders-model","text":"macros/macro_turnover.sql {% macro turnover() %} ( (base_price * quantity - rebate) * CASE currency WHEN 'EUR' THEN 1 WHEN 'USD' THEN 1.1 END ) {% endmacro %} models/institute/int__sales.sql SELECT orders.* , customers.customer_name , countries.country_name , {{ turnover() }} AS turnover FROM {{ ref(\"stg__orders\") }} AS orders INNER JOIN {{ ref(\"stg__customers\") }} AS customers ON customers.customer_id = orders.customer_id INNER JOIN {{ ref(\"stg__countries\") }} AS countries ON customers.customer_country = countries.country_code WHERE TRUE {% if var(\"order_filter\") %} AND order_datetime > '{{ var(\"order_filter\") }}' {% endif %}","title":"Create and use a macro to compute the turnover of orders in the int__orders model"},{"location":"module_08/lab-1/index.html","text":"Task Create a simple package structure and move your macro Todo Create a new folder at the same level of your current project to hold your custom dbt package In this folder, copy your dbt_project.yml files, and create a macros directory Edit the dbt_project file to remove vars, models and seed configuration and change the project name to the name of the package Import this package in your dbt project Edit your model to use the macro from your package Bonus Move the seeds to the package Check your seeds configuration to make sure they are written in the correct dataset","title":"Tasks"},{"location":"module_08/lab-1/index.html#task","text":"Create a simple package structure and move your macro","title":"Task"},{"location":"module_08/lab-1/index.html#todo","text":"Create a new folder at the same level of your current project to hold your custom dbt package In this folder, copy your dbt_project.yml files, and create a macros directory Edit the dbt_project file to remove vars, models and seed configuration and change the project name to the name of the package Import this package in your dbt project Edit your model to use the macro from your package","title":"Todo"},{"location":"module_08/lab-1/index.html#bonus","text":"Move the seeds to the package Check your seeds configuration to make sure they are written in the correct dataset","title":"Bonus"},{"location":"module_08/lab-1/SOLUTION.html","text":"Solution Create a new folder at the same level of your current project to hold your custom dbt package In this folder, copy your dbt_project.yml files, and create a macros directory You can put the folder wherever you want on your workstation, but remember the path to include it in the dependencies.yml file. Edit the dbt_project Your dbt_project.yml can be as little as that: name: 'mypackage' version: '1.0.0' macro-paths: [\"macros\"] You don't need to import a profile or anything else in the project structure. Import this package in your dbt project In your dependencies.yml or packages.yml file, just add your package as a local one using the relative or absolute path of your package. packages: - package: dbt-labs/dbt_utils version: 1.1.1 - package: calogica/dbt_expectations version: 0.10.1 - local: ../mypackage Edit your model to use the macro from your package Anywhere you are using your macro, just prefix the call with the name of your package separated with a dot. SELECT *, {{ mypackage.turnover() }} FROM {{ ref(\"stg__orders\") }} Bonus Move the seeds to the package Edit the package dbt_project.yml file to include the seeds directory. Move the seeds to this directory, and remove them from your current project. Update your dependencies with dbt deps and check the seeds part your current project dbt_project.yml file. Make sure the target schema applies to all seeds, including the ones in packages. Run dbt seed to make sure your seeds are insert correctly.","title":"Solution"},{"location":"module_08/lab-1/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_08/lab-1/SOLUTION.html#create-a-new-folder-at-the-same-level-of-your-current-project-to-hold-your-custom-dbt-package","text":"","title":"Create a new folder at the same level of your current project to hold your custom dbt package"},{"location":"module_08/lab-1/SOLUTION.html#in-this-folder-copy-your-dbt_projectyml-files-and-create-a-macros-directory","text":"You can put the folder wherever you want on your workstation, but remember the path to include it in the dependencies.yml file.","title":"In this folder, copy your dbt_project.yml files, and create a macros directory"},{"location":"module_08/lab-1/SOLUTION.html#edit-the-dbt_project","text":"Your dbt_project.yml can be as little as that: name: 'mypackage' version: '1.0.0' macro-paths: [\"macros\"] You don't need to import a profile or anything else in the project structure.","title":"Edit the dbt_project"},{"location":"module_08/lab-1/SOLUTION.html#import-this-package-in-your-dbt-project","text":"In your dependencies.yml or packages.yml file, just add your package as a local one using the relative or absolute path of your package. packages: - package: dbt-labs/dbt_utils version: 1.1.1 - package: calogica/dbt_expectations version: 0.10.1 - local: ../mypackage","title":"Import this package in your dbt project"},{"location":"module_08/lab-1/SOLUTION.html#edit-your-model-to-use-the-macro-from-your-package","text":"Anywhere you are using your macro, just prefix the call with the name of your package separated with a dot. SELECT *, {{ mypackage.turnover() }} FROM {{ ref(\"stg__orders\") }}","title":"Edit your model to use the macro from your package"},{"location":"module_08/lab-1/SOLUTION.html#bonus","text":"","title":"Bonus"},{"location":"module_08/lab-1/SOLUTION.html#move-the-seeds-to-the-package","text":"Edit the package dbt_project.yml file to include the seeds directory. Move the seeds to this directory, and remove them from your current project. Update your dependencies with dbt deps and check the seeds part your current project dbt_project.yml file. Make sure the target schema applies to all seeds, including the ones in packages. Run dbt seed to make sure your seeds are insert correctly.","title":"Move the seeds to the package"},{"location":"module_09/lab-1/index.html","text":"Task Add tests in your dbt code to make your life easier Todo Add a test to make sure that customer_id is unique in your source Add another test to make sure that order_status is in the list of accepted values: COMPLETED CANCELLED PROCESSING WAITING_PAYMENT SHIPPED Remove one of the accepted value and run dbt Rename this test for better readability in the log Create a singular test to make sure there are always at least 2 rows in the int__orders model Using dbt-hub, install the dbt-utils and dbt-expectations packages Use one of this package to make sure that int__orders always has the \"turnover\" column and that customer_name is never an empty string Replace your singular test with a generic test from one of the installed packages","title":"Tasks"},{"location":"module_09/lab-1/index.html#task","text":"Add tests in your dbt code to make your life easier","title":"Task"},{"location":"module_09/lab-1/index.html#todo","text":"Add a test to make sure that customer_id is unique in your source Add another test to make sure that order_status is in the list of accepted values: COMPLETED CANCELLED PROCESSING WAITING_PAYMENT SHIPPED Remove one of the accepted value and run dbt Rename this test for better readability in the log Create a singular test to make sure there are always at least 2 rows in the int__orders model Using dbt-hub, install the dbt-utils and dbt-expectations packages Use one of this package to make sure that int__orders always has the \"turnover\" column and that customer_name is never an empty string Replace your singular test with a generic test from one of the installed packages","title":"Todo"},{"location":"module_09/lab-1/SOLUTION.html","text":"Solution Add a test to make sure that customer_id is unique in your source models/institute/__source.yml sources: - name: sales database: sfeir schema: sales tables: - name: customers columns: - name: customer_id tests: - unique Add another test to make sure that order_status is in the list of accepted values: models/institute/__source.yml sources: - name: sales database: sfeir schema: sales tables: - name: orders columns: - name: order_status tests: - accepted_values: values: ['COMPLETED', 'CANCELLED', 'PROCESSING', 'WAITING_PAYMENT', 'SHIPPED'] name: test_order_status_values Create a singular test to make sure there are always at least 100 rows in the int__orders model tests/assert_row_count_orders.sql SELECT * FROM ( SELECT count(*) AS C FROM {{ ref(\"int__orders\") }} ) AS _ WHERE _.C < 2 Install the dbt_utils and dbt_expectations packages packages.yml packages: - package: dbt-labs/dbt_utils version: 1.1.1 - package: calogica/dbt_expectations version: 0.10.1 $ dbt deps Use one of this package to make sure that int__orders always has the \"turnover\" column models/institute/__models.yml models: - name: int__orders tests: - dbt_expectations.expect_table_columns_to_contain_set: column_list: [\"turnover\"] columns: - name: customer_name tests: - dbt_utils.not_empty_string Replace your singular test with a generic test from one of the installed packages models/institute/__models.yml models: - name: int__orders tests: - dbt_expectations.expect_table_row_count_to_be_between: min_value: 2 Don't forget to remove (or disable) your singular test to avoid redundancy.","title":"Solution"},{"location":"module_09/lab-1/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_09/lab-1/SOLUTION.html#add-a-test-to-make-sure-that-customer_id-is-unique-in-your-source","text":"models/institute/__source.yml sources: - name: sales database: sfeir schema: sales tables: - name: customers columns: - name: customer_id tests: - unique","title":"Add a test to make sure that customer_id is unique in your source"},{"location":"module_09/lab-1/SOLUTION.html#add-another-test-to-make-sure-that-order_status-is-in-the-list-of-accepted-values","text":"models/institute/__source.yml sources: - name: sales database: sfeir schema: sales tables: - name: orders columns: - name: order_status tests: - accepted_values: values: ['COMPLETED', 'CANCELLED', 'PROCESSING', 'WAITING_PAYMENT', 'SHIPPED'] name: test_order_status_values","title":"Add another test to make sure that order_status is in the list of accepted values:"},{"location":"module_09/lab-1/SOLUTION.html#create-a-singular-test-to-make-sure-there-are-always-at-least-100-rows-in-the-int__orders-model","text":"tests/assert_row_count_orders.sql SELECT * FROM ( SELECT count(*) AS C FROM {{ ref(\"int__orders\") }} ) AS _ WHERE _.C < 2","title":"Create a singular test to make sure there are always at least 100 rows in the int__orders model"},{"location":"module_09/lab-1/SOLUTION.html#install-the-dbt_utils-and-dbt_expectations-packages","text":"packages.yml packages: - package: dbt-labs/dbt_utils version: 1.1.1 - package: calogica/dbt_expectations version: 0.10.1 $ dbt deps","title":"Install the dbt_utils and dbt_expectations packages"},{"location":"module_09/lab-1/SOLUTION.html#use-one-of-this-package-to-make-sure-that-int__orders-always-has-the-turnover-column","text":"models/institute/__models.yml models: - name: int__orders tests: - dbt_expectations.expect_table_columns_to_contain_set: column_list: [\"turnover\"] columns: - name: customer_name tests: - dbt_utils.not_empty_string","title":"Use one of this package to make sure that int__orders always has the \"turnover\" column"},{"location":"module_09/lab-1/SOLUTION.html#replace-your-singular-test-with-a-generic-test-from-one-of-the-installed-packages","text":"models/institute/__models.yml models: - name: int__orders tests: - dbt_expectations.expect_table_row_count_to_be_between: min_value: 2 Don't forget to remove (or disable) your singular test to avoid redundancy.","title":"Replace your singular test with a generic test from one of the installed packages"},{"location":"module_10/lab-1/index.html","text":"Task Add contracts and versions to existing models from your warehouse Todo Contracts Add a contract with data types to the stg__orders model Run dbt to make sure your contract is valid Add / Remove a colum definition in your contract and see what happens Add a compound primary key to this model Add contraints to columns following the specs below: customer_id cannot be null order_id must be > 0 Versions Refactor your property file to include a first version if your int__orders model Add a new version of int__orders Add a new total_price computed field, without rebate Remove the country_name field Do not make this new version the default one Create a mart model and point to the default version of int__orders Update your mart model to pin the new, not yet official version of int__orders Add a closed or overdue deprecation date to the first version if your model Run dbt and look at the recommendations in the log","title":"Tasks"},{"location":"module_10/lab-1/index.html#task","text":"Add contracts and versions to existing models from your warehouse","title":"Task"},{"location":"module_10/lab-1/index.html#todo","text":"","title":"Todo"},{"location":"module_10/lab-1/index.html#contracts","text":"Add a contract with data types to the stg__orders model Run dbt to make sure your contract is valid Add / Remove a colum definition in your contract and see what happens Add a compound primary key to this model Add contraints to columns following the specs below: customer_id cannot be null order_id must be > 0","title":"Contracts"},{"location":"module_10/lab-1/index.html#versions","text":"Refactor your property file to include a first version if your int__orders model Add a new version of int__orders Add a new total_price computed field, without rebate Remove the country_name field Do not make this new version the default one Create a mart model and point to the default version of int__orders Update your mart model to pin the new, not yet official version of int__orders Add a closed or overdue deprecation date to the first version if your model Run dbt and look at the recommendations in the log","title":"Versions"},{"location":"module_10/lab-1/SOLUTION.html","text":"Solution Contracts Add a contract with data types to the stg__orders model __models.yml models: - name: stg__orders config: materialized: table contract: enforced: true columns: - name: order_id data_type: int - name: order_line_id data_type: int - name: product_id data_type: int - name: base_price data_type: float - name: quantity data_type: int - name: rebate data_type: float - name: currency data_type: char(3) - name: order_datetime data_type: timestamp - name: order_status data_type: varchar(32) - name: customer_id data_type: int Add / Remove a colum definition in your contract and see what happens dbt should fail and output the defaults in the contract for easy fixing. Add a compound primary key to this model In the model property file, add the following as primary key: ... constraints: - type: primary_key columns: [ 'order_id', 'order_line_id' ] ... Add contraints to columns following the specs below In the model property file, at the column level, add the following constraints: ... - name: order_id data_type: int constraints: - type: check expression: 'order_id > 0' - name: customer_id data_type: int constraints: - type: not_null ... Versions Refactor your property and SQL files to include a first version if your int__orders model models: - name: int__orders tests: - dbt_expectations.expect_table_columns_to_contain_set: column_list: [ \"turnover\" ] - dbt_expectations.expect_table_row_count_to_be_between: min_value: 2 versions: - v: 1 If you include tests in a specific version, they will only run for this version and not the inherited ones. Add a new version of int__orders models: - name: int__orders latest_version: 1 tests: - dbt_expectations.expect_table_columns_to_contain_set: column_list: [ \"turnover\" ] - dbt_expectations.expect_table_row_count_to_be_between: min_value: 2 versions: - v: 1 - v: 2 columns: - include: all exclude: [country_name] - name: total_price Create a mart model and point to the default version of int__orders -- models/institute/orders.sql SELECT * FROM {{ ref('int__orders') }} When you run this model, you should see a message from dbt about an unpinned recent version not marked as latest. Update your mart model and pin the new, not yet official version of int__orders -- models/institute/orders.sql SELECT * FROM {{ ref('int__orders', version=2) }} Add a near-future or overdue deprecation date to the first version if your model models: - name: int__orders latest_version: 1 tests: - dbt_expectations.expect_table_columns_to_contain_set: column_list: [ \"turnover\" ] - dbt_expectations.expect_table_row_count_to_be_between: min_value: 2 versions: - v: 1 deprecation_date: 2023-12-31 00:00:00.00+00:00 - v: 2 columns: - include: all exclude: [country_name] - name: total_price","title":"Solution"},{"location":"module_10/lab-1/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_10/lab-1/SOLUTION.html#contracts","text":"","title":"Contracts"},{"location":"module_10/lab-1/SOLUTION.html#add-a-contract-with-data-types-to-the-stg__orders-model","text":"__models.yml models: - name: stg__orders config: materialized: table contract: enforced: true columns: - name: order_id data_type: int - name: order_line_id data_type: int - name: product_id data_type: int - name: base_price data_type: float - name: quantity data_type: int - name: rebate data_type: float - name: currency data_type: char(3) - name: order_datetime data_type: timestamp - name: order_status data_type: varchar(32) - name: customer_id data_type: int","title":"Add a contract with data types to the stg__orders model"},{"location":"module_10/lab-1/SOLUTION.html#add-remove-a-colum-definition-in-your-contract-and-see-what-happens","text":"dbt should fail and output the defaults in the contract for easy fixing.","title":"Add / Remove a colum definition in your contract and see what happens"},{"location":"module_10/lab-1/SOLUTION.html#add-a-compound-primary-key-to-this-model","text":"In the model property file, add the following as primary key: ... constraints: - type: primary_key columns: [ 'order_id', 'order_line_id' ] ...","title":"Add a compound primary key to this model"},{"location":"module_10/lab-1/SOLUTION.html#add-contraints-to-columns-following-the-specs-below","text":"In the model property file, at the column level, add the following constraints: ... - name: order_id data_type: int constraints: - type: check expression: 'order_id > 0' - name: customer_id data_type: int constraints: - type: not_null ...","title":"Add contraints to columns following the specs below"},{"location":"module_10/lab-1/SOLUTION.html#versions","text":"","title":"Versions"},{"location":"module_10/lab-1/SOLUTION.html#refactor-your-property-and-sql-files-to-include-a-first-version-if-your-int__orders-model","text":"models: - name: int__orders tests: - dbt_expectations.expect_table_columns_to_contain_set: column_list: [ \"turnover\" ] - dbt_expectations.expect_table_row_count_to_be_between: min_value: 2 versions: - v: 1 If you include tests in a specific version, they will only run for this version and not the inherited ones.","title":"Refactor your property and SQL files to include a first version if your int__orders model"},{"location":"module_10/lab-1/SOLUTION.html#add-a-new-version-of-int__orders","text":"models: - name: int__orders latest_version: 1 tests: - dbt_expectations.expect_table_columns_to_contain_set: column_list: [ \"turnover\" ] - dbt_expectations.expect_table_row_count_to_be_between: min_value: 2 versions: - v: 1 - v: 2 columns: - include: all exclude: [country_name] - name: total_price","title":"Add a new version of int__orders"},{"location":"module_10/lab-1/SOLUTION.html#create-a-mart-model-and-point-to-the-default-version-of-int__orders","text":"-- models/institute/orders.sql SELECT * FROM {{ ref('int__orders') }} When you run this model, you should see a message from dbt about an unpinned recent version not marked as latest.","title":"Create a mart model and point to the default version of int__orders"},{"location":"module_10/lab-1/SOLUTION.html#update-your-mart-model-and-pin-the-new-not-yet-official-version-of-int__orders","text":"-- models/institute/orders.sql SELECT * FROM {{ ref('int__orders', version=2) }}","title":"Update your mart model and pin the new, not yet official version of int__orders"},{"location":"module_10/lab-1/SOLUTION.html#add-a-near-future-or-overdue-deprecation-date-to-the-first-version-if-your-model","text":"models: - name: int__orders latest_version: 1 tests: - dbt_expectations.expect_table_columns_to_contain_set: column_list: [ \"turnover\" ] - dbt_expectations.expect_table_row_count_to_be_between: min_value: 2 versions: - v: 1 deprecation_date: 2023-12-31 00:00:00.00+00:00 - v: 2 columns: - include: all exclude: [country_name] - name: total_price","title":"Add a near-future or overdue deprecation date to the first version if your model"},{"location":"module_11/lab-1/index.html","text":"Task Add documentation to your project and navigate through the lineage Todo Documentation Add inline documentation to your project Document one of your source tables Document one of your model Document your macro Don't repeat yourself and consistently document your \"order_status\" field across the project Generate your documentation and enjoy","title":"Tasks"},{"location":"module_11/lab-1/index.html#task","text":"Add documentation to your project and navigate through the lineage","title":"Task"},{"location":"module_11/lab-1/index.html#todo","text":"","title":"Todo"},{"location":"module_11/lab-1/index.html#documentation","text":"Add inline documentation to your project Document one of your source tables Document one of your model Document your macro Don't repeat yourself and consistently document your \"order_status\" field across the project Generate your documentation and enjoy","title":"Documentation"},{"location":"module_11/lab-1/SOLUTION.html","text":"Solution Documentation Add inline documentation to your project You can easily add inline documentation in the yaml property files: models/institute/__sources.yml sources: - name: sales schema: sales tables: - name: orders columns: - name: order_id description: \"ID of order in SAP\" - name: order_line_id description: \"Line ID of in SAP\" - name: base_price description: \"Raw selling price in EUR\" - name: order_status description: \"| Status of order. Allowed values: COMPLETED, CANCELLED, PROCESSING, WAITING_PAYMENT, SHIPPED\" Replace the inline documenation with doc blocks Use a markdown file replace your inline block with a call with the doc() macro. models/institute/__doc.md % docs column__orders__order_status %} Status of order. _Allowed values_: COMPLETED, CANCELLED, PROCESSING, WAITING_PAYMENT, SHIPPED {% enddocs %} models/institute/__sources.yml sources: - name: sales schema: sales tables: - name: orders columns: - name: order_id description: \"ID of order in SAP\" - name: order_line_id description: \"Line ID of in SAP\" - name: base_price description: \"Raw selling price in EUR\" - name: order_status description: '{{ doc(\"column__orders__order_status\") }}' Generate and browse your documentation dbt docs generate && dbt docs serve","title":"Solution"},{"location":"module_11/lab-1/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_11/lab-1/SOLUTION.html#documentation","text":"","title":"Documentation"},{"location":"module_11/lab-1/SOLUTION.html#add-inline-documentation-to-your-project","text":"You can easily add inline documentation in the yaml property files: models/institute/__sources.yml sources: - name: sales schema: sales tables: - name: orders columns: - name: order_id description: \"ID of order in SAP\" - name: order_line_id description: \"Line ID of in SAP\" - name: base_price description: \"Raw selling price in EUR\" - name: order_status description: \"| Status of order. Allowed values: COMPLETED, CANCELLED, PROCESSING, WAITING_PAYMENT, SHIPPED\"","title":"Add inline documentation to your project"},{"location":"module_11/lab-1/SOLUTION.html#replace-the-inline-documenation-with-doc-blocks","text":"Use a markdown file replace your inline block with a call with the doc() macro. models/institute/__doc.md % docs column__orders__order_status %} Status of order. _Allowed values_: COMPLETED, CANCELLED, PROCESSING, WAITING_PAYMENT, SHIPPED {% enddocs %} models/institute/__sources.yml sources: - name: sales schema: sales tables: - name: orders columns: - name: order_id description: \"ID of order in SAP\" - name: order_line_id description: \"Line ID of in SAP\" - name: base_price description: \"Raw selling price in EUR\" - name: order_status description: '{{ doc(\"column__orders__order_status\") }}'","title":"Replace the inline documenation with doc blocks"},{"location":"module_11/lab-1/SOLUTION.html#generate-and-browse-your-documentation","text":"dbt docs generate && dbt docs serve","title":"Generate and browse your documentation"},{"location":"module_12/lab-1/index.html","text":"Task Add analysis and exposures in your project Todo Analysis Add a simple request of your choice in the analysis direction using ref() or source() Use dbt compile to generate the code and run request in you database Exposures Declare a fake exposure in your project, with a few dependencies Use this exposures to run dbt and materialize all the dependencies Hooks Create an index on stg__orders.customer_id using a pre-hook","title":"Tasks"},{"location":"module_12/lab-1/index.html#task","text":"Add analysis and exposures in your project","title":"Task"},{"location":"module_12/lab-1/index.html#todo","text":"","title":"Todo"},{"location":"module_12/lab-1/index.html#analysis","text":"Add a simple request of your choice in the analysis direction using ref() or source() Use dbt compile to generate the code and run request in you database","title":"Analysis"},{"location":"module_12/lab-1/index.html#exposures","text":"Declare a fake exposure in your project, with a few dependencies Use this exposures to run dbt and materialize all the dependencies","title":"Exposures"},{"location":"module_12/lab-1/index.html#hooks","text":"Create an index on stg__orders.customer_id using a pre-hook","title":"Hooks"},{"location":"module_12/lab-1/SOLUTION.html","text":"Solution Analysis Add a simple request of your choice in the analysis direction using ref() or source() analysis/total_base_price.sql SELECT count(*), SUM(base_price) FROM {{int__orders}} Exposures Declare a fake exposure in your project, with a few dependencies models/__exposures.yml - name: monitoring_rsp label: \"Recommended Selling Price Monitoring\" type: dashboard maturity: low url: https://app.powerbi.com/thisisnotarealurl description: \"A great dashboard to follow RSP\" depends_on: - ref('int__orders') - source('categories') owner: name: Sophie Fonfec email: sophie@fonfec.com Use this exposures to run dbt and materialize all the dependencies dbt run --select +exposure:monitoring_rsp Hooks Create an index on stg__orders.customer_id using a post-hook Add a post_hook to your model like this: {{ config( post_hook = \"CREATE INDEX IF NOT EXISTS customer_idx ON {{ this }} (customer_id);\" ) }} SELECT * FROM {{ source(\"sales\", \"orders\") }} Look in the logs to effectively see dbt ran the query to create the index.","title":"Solution"},{"location":"module_12/lab-1/SOLUTION.html#solution","text":"","title":"Solution"},{"location":"module_12/lab-1/SOLUTION.html#analysis","text":"","title":"Analysis"},{"location":"module_12/lab-1/SOLUTION.html#add-a-simple-request-of-your-choice-in-the-analysis-direction-using-ref-or-source","text":"analysis/total_base_price.sql SELECT count(*), SUM(base_price) FROM {{int__orders}}","title":"Add a simple request of your choice in the analysis direction using ref() or source()"},{"location":"module_12/lab-1/SOLUTION.html#exposures","text":"","title":"Exposures"},{"location":"module_12/lab-1/SOLUTION.html#declare-a-fake-exposure-in-your-project-with-a-few-dependencies","text":"models/__exposures.yml - name: monitoring_rsp label: \"Recommended Selling Price Monitoring\" type: dashboard maturity: low url: https://app.powerbi.com/thisisnotarealurl description: \"A great dashboard to follow RSP\" depends_on: - ref('int__orders') - source('categories') owner: name: Sophie Fonfec email: sophie@fonfec.com","title":"Declare a fake exposure in your project, with a few dependencies"},{"location":"module_12/lab-1/SOLUTION.html#use-this-exposures-to-run-dbt-and-materialize-all-the-dependencies","text":"dbt run --select +exposure:monitoring_rsp","title":"Use this exposures to run dbt and materialize all the dependencies"},{"location":"module_12/lab-1/SOLUTION.html#hooks","text":"","title":"Hooks"},{"location":"module_12/lab-1/SOLUTION.html#create-an-index-on-stg__orderscustomer_id-using-a-post-hook","text":"Add a post_hook to your model like this: {{ config( post_hook = \"CREATE INDEX IF NOT EXISTS customer_idx ON {{ this }} (customer_id);\" ) }} SELECT * FROM {{ source(\"sales\", \"orders\") }} Look in the logs to effectively see dbt ran the query to create the index.","title":"Create an index on stg__orders.customer_id using a post-hook"}]}